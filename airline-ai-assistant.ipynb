{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "858bf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8df8eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "MODEL = \"gemini-2.5-flash\"\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42d567be",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant for an airline company called Flightly. \n",
    "Give short, courteous answers, no more than one sentence. \n",
    "Always be polite and professional in your responses.\n",
    "You only know about airline data. If you don't know the answer, say so.\n",
    "Assume that all flyghts are from a unique origin, so each flight has a unique price associated with the city\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "102c054c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat(message, history):\n",
    "    google_messages = []\n",
    "\n",
    "    google_messages.append({\"role\": \"user\", \"parts\": [{\"text\": system_message}]})\n",
    "    google_messages.append({\"role\": \"model\", \"parts\": [{\"text\": \"Entendido, seguir√© esas instrucciones.\"}]})\n",
    "\n",
    "    for h in history:\n",
    "        role = \"user\" if h[\"role\"] == \"user\" else \"model\"\n",
    "        google_messages.append({\n",
    "            \"role\": role,\n",
    "            \"parts\": [{\"text\": h[\"content\"]}]\n",
    "        })\n",
    "    google_messages.append({\"role\": \"user\", \"parts\": [{\"text\": message}]})\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=google_messages\n",
    "    )\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "048b8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\"london\": \"$800\", \"paris\": \"$900\", \"tokyo\": \"$1400\", \"berlin\": \"$500\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool called for city {destination_city}\")\n",
    "    price = ticket_prices.get(destination_city.lower(), \"Unknow ticket price\")\n",
    "    return f\"The price of a ticket to {destination_city} is {price}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2dc56705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool called for city London\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The price of a ticket to London is $800'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price(\"London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b16e18a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58c7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [types.Tool(function_declarations=[types.FunctionDeclaration(\n",
    "    name=\"get_ticket_price\",\n",
    "    description=\"Get the price of a return ticket to the destination city\",\n",
    "    parameters=types.Schema(\n",
    "        type=types.Type.OBJECT,\n",
    "        properties={\"destination_city\": types.Schema(type=types.Type.STRING, description=\"The city that the customer wants to travel to\")},\n",
    "        required=[\"destination_city\"]\n",
    "    ),\n",
    "    name=\"set_ticket_price\",\n",
    "    description=\"Set the price of a return ticket to the destination city\",\n",
    "    parameters=types.Schema(\n",
    "        type=types.Type.OBJECT,\n",
    "        properties={\"destination_city\": types.Schema(type=types.Type.STRING, description=\"The city that the customer wants to travel to\")},\n",
    "        required=[\"destination_city\"]\n",
    "    )\n",
    ")])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0713e6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(\n",
       "   function_declarations=[\n",
       "     FunctionDeclaration(\n",
       "       description='Get the price of a return ticket to the destination city',\n",
       "       name='get_ticket_price',\n",
       "       parameters=Schema(\n",
       "         properties={\n",
       "           'destination_city': Schema(\n",
       "             description='The city that the customer wants to travel to',\n",
       "             type=<Type.STRING: 'STRING'>\n",
       "           )\n",
       "         },\n",
       "         required=[\n",
       "           'destination_city',\n",
       "         ],\n",
       "         type=<Type.OBJECT: 'OBJECT'>\n",
       "       )\n",
       "     ),\n",
       "   ]\n",
       " )]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "250c2811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    if tool_call.function.name == \"get_ticket_price\":\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        city = arguments.get('destination_city')\n",
    "        price_details = get_ticket_price(city)\n",
    "        response = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": price_details,\n",
    "            \"tool_call_id\": tool_call.id\n",
    "        }\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "28fa3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    gemini_history = []\n",
    "    if not history:\n",
    "        gemini_history.append({\"role\": \"user\", \"parts\": [{\"text\": system_message}]})\n",
    "    for h in history:\n",
    "        role = \"user\" if h[\"role\"] == \"user\" else \"model\"\n",
    "        if isinstance(h[\"content\"], list):\n",
    "            parts = [{\"text\": item[\"text\"]} for item in h[\"content\"] if item.get(\"type\") == \"text\"]\n",
    "        else:\n",
    "            parts = [{\"text\": h[\"content\"]}]\n",
    "        gemini_history.append({\"role\": role, \"parts\": parts})\n",
    "    config = types.GenerateContentConfig(tools=tools)\n",
    "    chat_session = client.chats.create(model=MODEL, config=config, history=gemini_history)\n",
    "    response = chat_session.send_message(message)\n",
    "    part = response.candidates[0].content.parts[0]\n",
    "    if hasattr(part, 'function_call') and part.function_call:\n",
    "        call = part.function_call\n",
    "        if call.name == 'get_ticket_price':\n",
    "            city = call.args['destination_city']\n",
    "            price = get_ticket_price(city)\n",
    "            tool_part = types.Part(function_response=types.FunctionResponse(name=call.name, response={\"result\": price}))\n",
    "            tool_response = chat_session.send_message(tool_part)\n",
    "            return tool_response.candidates[0].content.parts[0].text\n",
    "    return part.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ac536c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7875\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool called for city London\n",
      "Tool called for city Paris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\queueing.py\", line 766, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\route_utils.py\", line 355, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\blocks.py\", line 2152, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\blocks.py\", line 1627, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\utils.py\", line 1001, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\chat_interface.py\", line 544, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\chat_interface.py\", line 905, in _submit_fn\n",
      "    response = await run_sync(self.fn, *inputs, limiter=self.limiter)  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\anyio\\to_thread.py\", line 61, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2525, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\anyio\\_backends\\_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\matias\\AppData\\Local\\Temp\\ipykernel_7268\\2325146606.py\", line 22, in chat\n",
      "    tool_response = chat_session.send_message(tool_part)\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\chats.py\", line 252, in send_message\n",
      "    response = self._modules.generate_content(\n",
      "        model=self._model,\n",
      "        contents=self._curated_history + [input_content],  # type: ignore[arg-type]\n",
      "        config=config if config else self._config,\n",
      "    )\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\models.py\", line 5200, in generate_content\n",
      "    return self._generate_content(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        model=model, contents=contents, config=parsed_config\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\models.py\", line 3997, in _generate_content\n",
      "    response = self._api_client.request(\n",
      "        'post', path, request_dict, http_options\n",
      "    )\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\_api_client.py\", line 1375, in request\n",
      "    response = self._request(http_request, http_options, stream=False)\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\_api_client.py\", line 1211, in _request\n",
      "    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]\n",
      "           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\tenacity\\__init__.py\", line 477, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\tenacity\\__init__.py\", line 378, in iter\n",
      "    result = action(retry_state)\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\tenacity\\__init__.py\", line 420, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\tenacity\\__init__.py\", line 187, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\matias\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\concurrent\\futures\\_base.py\", line 443, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\matias\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\concurrent\\futures\\_base.py\", line 395, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\tenacity\\__init__.py\", line 480, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\_api_client.py\", line 1188, in _request_once\n",
      "    errors.APIError.raise_for_response(response)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\errors.py\", line 121, in raise_for_response\n",
      "    cls.raise_error(response.status_code, response_json, response)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\errors.py\", line 146, in raise_error\n",
      "    raise ClientError(status_code, response_json, response)\n",
      "google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 58.030281554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '58s'}]}}\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af7cb66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = \"prices.db\"\n",
    "\n",
    "with sqlite3.connect(DB) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('CREATE TABLE IF NOT EXISTS prices (city TEXT PRIMARY KEY, price REAL)')\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "809b2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticket_price(city):\n",
    "    print(f\"DATABASE TOOL CALLED: Getting price for {city}\", flush=True)\n",
    "    with sqlite3.connect(DB) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('SELECT price FROM prices WHERE city = ?', (city.lower(),))\n",
    "        result = cursor.fetchone()\n",
    "        return f\"Ticket price to {city} is ${result[0]}\" if result else \"No price data available for this city\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1d073922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATABASE TOOL CALLED: Getting price for London\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No price data available for this city'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price(\"London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "646229b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_ticket_price(city, price):\n",
    "    with sqlite3.connect(DB) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('INSERT INTO prices (city, price) VALUES (?, ?) ON CONFLICT(city) DO UPDATE SET price = ?', (city.lower(), price, price))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f9160922",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\"london\": \"$800\", \"paris\": \"$900\", \"tokyo\": \"$1400\", \"berlin\": \"$500\"}\n",
    "for city, price in ticket_prices.items():\n",
    "    set_ticket_price(city, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "12cd6915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATABASE TOOL CALLED: Getting price for Tokyo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ticket price to Tokyo is $$1400'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price(\"Tokyo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "db91c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATABASE TOOL CALLED: Getting price for TOKYO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\queueing.py\", line 766, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\route_utils.py\", line 355, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\blocks.py\", line 2152, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\blocks.py\", line 1627, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\utils.py\", line 1001, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\chat_interface.py\", line 544, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\gradio\\chat_interface.py\", line 905, in _submit_fn\n",
      "    response = await run_sync(self.fn, *inputs, limiter=self.limiter)  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\anyio\\to_thread.py\", line 61, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2525, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\anyio\\_backends\\_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\matias\\AppData\\Local\\Temp\\ipykernel_7268\\2325146606.py\", line 22, in chat\n",
      "    tool_response = chat_session.send_message(tool_part)\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\chats.py\", line 252, in send_message\n",
      "    response = self._modules.generate_content(\n",
      "        model=self._model,\n",
      "        contents=self._curated_history + [input_content],  # type: ignore[arg-type]\n",
      "        config=config if config else self._config,\n",
      "    )\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\models.py\", line 5200, in generate_content\n",
      "    return self._generate_content(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        model=model, contents=contents, config=parsed_config\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\models.py\", line 3997, in _generate_content\n",
      "    response = self._api_client.request(\n",
      "        'post', path, request_dict, http_options\n",
      "    )\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\_api_client.py\", line 1375, in request\n",
      "    response = self._request(http_request, http_options, stream=False)\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\_api_client.py\", line 1211, in _request\n",
      "    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]\n",
      "           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\tenacity\\__init__.py\", line 477, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\tenacity\\__init__.py\", line 378, in iter\n",
      "    result = action(retry_state)\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\tenacity\\__init__.py\", line 420, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\tenacity\\__init__.py\", line 187, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\matias\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\concurrent\\futures\\_base.py\", line 443, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\matias\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\concurrent\\futures\\_base.py\", line 395, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\tenacity\\__init__.py\", line 480, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\_api_client.py\", line 1188, in _request_once\n",
      "    errors.APIError.raise_for_response(response)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\errors.py\", line 121, in raise_for_response\n",
      "    cls.raise_error(response.status_code, response_json, response)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matias\\AppData\\Roaming\\Python\\Python314\\site-packages\\google\\genai\\errors.py\", line 146, in raise_error\n",
      "    raise ClientError(status_code, response_json, response)\n",
      "google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 50.941552432s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '50s'}]}}\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
